{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Projeto 1 - Ci√™ncia dos Dados</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: *Caio Emmanuel*\n",
    "\n",
    "Nome: *Larissa*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introdu√ß√£o</h3>\n",
    "\n",
    "Para realizar este trabalho, a dupla escolhe como tema a ser pesquisado as Olimp√≠adas de 2020 que ocorrer√£o no Jap√£o por este ser um tema atual devido √† prepara√ß√£o em velocidade recordista que o pa√≠s teve para receber o evento e agora mais ainda devido √† doen√ßa viral Corona que amea√ßa a realiza√ß√£o do mesmo.\n",
    "\n",
    "Classificamos os *tweets* obtidos como 0 ou 1, sendo 0 *tweets* irrelevantes sobre o assunto e 1 o contr√°rio.\n",
    "\n",
    "Vale ressaltar que usamos o artif√≠cio matem√°tico probabil√≠stico conhecido como *m√©todo de Naive-Bayes* para fazer previs√µes mais precisas sobre uma base de dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Crit√©rios de classifica√ß√£o</h3>\n",
    "\n",
    "Classificamos como relevante aqueles *tweets* que remetem a assuntos atuais sobre a Olimp√≠ada, como os atletas convidados, poss√≠vel cancelamento, etc.\n",
    "\n",
    "E classificamos como irrelevante aqueles que n√£o t√™m rela√ß√£o com o evento mas tem com algum hom√¥nimo (olimp√≠adas cient√≠ficas, regionais, olimp√≠adas passadas,etc.), al√©m daqueles que julgamos n√£o acrescentar nada ao assunto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Carregando algumas bibliotecas e o dataset:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "/home/caio/Documents/cdados/cdados_proj1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treino = pd.read_excel('olympics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rt @saitomri: i wrote about baseball. really. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>rt @ndidi_amakaa: @solaadio olu leave your mot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@wintersdancer they don‚Äôt want to lose the oly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>exclusive: indonesia considers 2032 olympics b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>the tentacles of canceling the tokyo olympics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classification\n",
       "0  rt @saitomri: i wrote about baseball. really. ...               0\n",
       "1  rt @ndidi_amakaa: @solaadio olu leave your mot...               0\n",
       "2  @wintersdancer they don‚Äôt want to lose the oly...               1\n",
       "3  exclusive: indonesia considers 2032 olympics b...               0\n",
       "4  the tentacles of canceling the tokyo olympics ...               1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Realizando limpeza dos dados</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "# Fun√ß√£o que remove pontua√ß√£o\n",
    "def cleanup(text):\n",
    "    punctuation = '[\\/!-.:?;]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "for i in range(500):\n",
    "    # Removendo pontua√ß√£o\n",
    "    dados_treino = dados_treino.replace(dados_treino['Treinamento'][i], cleanup(dados_treino['Treinamento'][i]))\n",
    "    \n",
    "    # Removendo '\\n'\n",
    "    dados_treino['Treinamento'] = dados_treino['Treinamento'].str.replace('[\\n]','')\n",
    "    \n",
    "    # Removendo 'rt'\n",
    "    if dados_treino['Treinamento'][i][:2] == 'rt':\n",
    "        dados_treino = dados_treino.replace(dados_treino['Treinamento'][i], dados_treino['Treinamento'][i][3:])\n",
    "        \n",
    "    # Deixando todas as letras min√∫sculas:\n",
    "    dados_treino = dados_treino.replace(dados_treino['Treinamento'][i], dados_treino['Treinamento'][i].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@saitomri i wrote about baseball really httpst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@ndidi_amakaa @solaadio olu leave your mother ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@wintersdancer they don‚Äôt want to lose the oly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>exclusive indonesia considers 2032 olympics bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>the tentacles of canceling the tokyo olympics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>highspeed camera used by nazis to both accurat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>indonesia considers 2032 olympics bid for new ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>@gailwalden6 i would like to apply to be in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>the year is 2024¬†üîÆwomens world no 1 is üë©______...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>@kagutamuseveni this is a joke and total waste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Classification\n",
       "0    @saitomri i wrote about baseball really httpst...               0\n",
       "1    @ndidi_amakaa @solaadio olu leave your mother ...               0\n",
       "2    @wintersdancer they don‚Äôt want to lose the oly...               1\n",
       "3    exclusive indonesia considers 2032 olympics bi...               0\n",
       "4    the tentacles of canceling the tokyo olympics ...               1\n",
       "..                                                 ...             ...\n",
       "495  highspeed camera used by nazis to both accurat...               0\n",
       "496  indonesia considers 2032 olympics bid for new ...               0\n",
       "497  @gailwalden6 i would like to apply to be in th...               0\n",
       "498  the year is 2024¬†üîÆwomens world no 1 is üë©______...               0\n",
       "499  @kagutamuseveni this is a joke and total waste...               1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Separando o dataset em *tweets* relavantes e irrelevantes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@wintersdancer they don‚Äôt want to lose the oly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>the tentacles of canceling the tokyo olympics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>it is the olympic year and we as a team have p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>@imrahultrehan from practicing muay thai in he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>athletes aiming for gold medals or sports busi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>@skift olympics cancellation would spell heavy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>olympics torch lighting ceremony will be close...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>a lot of people stand to lose if olympics are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>tokyo 2020 has been dealt its first significan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>@kagutamuseveni this is a joke and total waste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Classification\n",
       "2    @wintersdancer they don‚Äôt want to lose the oly...               1\n",
       "4    the tentacles of canceling the tokyo olympics ...               1\n",
       "5    it is the olympic year and we as a team have p...               1\n",
       "9    @imrahultrehan from practicing muay thai in he...               1\n",
       "10   athletes aiming for gold medals or sports busi...               1\n",
       "..                                                 ...             ...\n",
       "478  @skift olympics cancellation would spell heavy...               1\n",
       "480  olympics torch lighting ceremony will be close...               1\n",
       "485  a lot of people stand to lose if olympics are ...               1\n",
       "487  tokyo 2020 has been dealt its first significan...               1\n",
       "499  @kagutamuseveni this is a joke and total waste...               1\n",
       "\n",
       "[178 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweets relevantes\n",
    "tweets_r = dados_treino.loc[(dados_treino.Classification == 1)]\n",
    "tweets_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets irrelevantes\n",
    "tweets_ir = dados_treino.loc[(dados_treino.Classification == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo a probabilidade de um *tweet* ser relevante (P_r) e irrelevante (P_ir) s√£o..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frequ√™ncia de tweets relevantes √©: 0.356\n",
      "A frequ√™ncia de tweets irrelevantes √©: 0.644\n"
     ]
    }
   ],
   "source": [
    "P_r = tweets_r.Treinamento.count()/dados_treino.Treinamento.count()\n",
    "P_ir = tweets_ir.Treinamento.count()/dados_treino.Treinamento.count()\n",
    "print('A frequ√™ncia de tweets relevantes √©: {0}' .format(P_r))\n",
    "print('A frequ√™ncia de tweets irrelevantes √©: {0}' .format(P_ir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculando frequ√™ncias relativas dentro de cada grupo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @wintersdancer\n",
       "1                  they\n",
       "2                 don‚Äôt\n",
       "3                  want\n",
       "4                    to\n",
       "             ...       \n",
       "3634            torture\n",
       "3635                yes\n",
       "3636                for\n",
       "3637                him\n",
       "3638    @kagutamuseveni\n",
       "Length: 3639, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criando texto com todos os tweets relevantes\n",
    "txt_r = ''\n",
    "for t in tweets_r['Treinamento']:\n",
    "    t = str(t)\n",
    "    txt_r += t\n",
    "\n",
    "# criando s√©rie com as palavras dos tweets relevantes\n",
    "words_r = pd.Series(txt_r.split())\n",
    "words_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the             0.061830\n",
       "olympics        0.035999\n",
       "to              0.028030\n",
       "of              0.019236\n",
       "for             0.018137\n",
       "                  ...   \n",
       "sars            0.000275\n",
       "running         0.000275\n",
       "shot            0.000275\n",
       "universities    0.000275\n",
       "eight           0.000275\n",
       "Length: 1378, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_r = words_r.value_counts(True)\n",
    "words_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_r.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the                0.050114\n",
       "olympics           0.028047\n",
       "to                 0.024060\n",
       "and                0.017796\n",
       "in                 0.017227\n",
       "                     ...   \n",
       "decontamination    0.000142\n",
       "@sinicouk          0.000142\n",
       "lyrics             0.000142\n",
       "vacations          0.000142\n",
       "1976               0.000142\n",
       "Length: 2672, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do mesmo jeito para os tweets irrelevantes:\n",
    "txt_ir = ''\n",
    "for t in tweets_ir['Treinamento']:\n",
    "    t = str(t)\n",
    "    txt_ir += t\n",
    "    \n",
    "words_ir = pd.Series(txt_ir.split())\n",
    "words_ir = words_ir.value_counts(True)\n",
    "words_ir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuma agora que as palavras que aparecem nos dois datasets anteriores sejam todas as palavras do Universo no Twitter (tweeverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = txt_r + txt_ir\n",
    "tweeverse_words = pd.Series(txt.split())\n",
    "tweeverse_words_frequencie = tweeverse_words.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the         0.054112\n",
       "olympics    0.030761\n",
       "to          0.025415\n",
       "for         0.017256\n",
       "of          0.017068\n",
       "              ...   \n",
       "rues        0.000094\n",
       "18          0.000094\n",
       "save        0.000094\n",
       "hsright     0.000094\n",
       "1976        0.000094\n",
       "Length: 3514, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeverse_words_frequencie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Realizando testes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fwit olympics https://t.co/72go6l7pkx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@jimodonnell2 it's certainly a supportable opi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@kapil857 @kapil857 any link to know how point...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rt @media_sai: what a superb performance by @s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rt @theeconomist: japan may have to cancel the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>study: tokyo 2020 cancellation could see japan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>japanese doctors report sharp falls in cases o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>rt @jimmfelton: ‚Äúvirus is bad, might have to c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>rt @drjitendrasingh: eight indian boxers inclu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>the international olympic committee and local ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  Classification\n",
       "0               fwit olympics https://t.co/72go6l7pkx               0\n",
       "1   @jimodonnell2 it's certainly a supportable opi...               1\n",
       "2   @kapil857 @kapil857 any link to know how point...               0\n",
       "3   rt @media_sai: what a superb performance by @s...               0\n",
       "4   rt @theeconomist: japan may have to cancel the...               1\n",
       "..                                                ...             ...\n",
       "95  study: tokyo 2020 cancellation could see japan...               1\n",
       "96  japanese doctors report sharp falls in cases o...               0\n",
       "97  rt @jimmfelton: ‚Äúvirus is bad, might have to c...               0\n",
       "98  rt @drjitendrasingh: eight indian boxers inclu...               1\n",
       "99  the international olympic committee and local ...               1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste = pd.read_excel('teste.xlsx')\n",
    "dados_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos realizar todo o processo de formata√ß√£o e encontra P_r e P_ir dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # Removendo pontua√ß√£o\n",
    "    dados_teste = dados_teste.replace(dados_teste['Teste'][i], cleanup(dados_teste['Teste'][i]))\n",
    "    \n",
    "    # Removendo '\\n'\n",
    "    dados_teste['Teste'] = dados_teste['Teste'].str.replace('[\\n]','')\n",
    "    \n",
    "    # Removendo 'rt'\n",
    "    if dados_teste['Teste'][i][:2] == 'rt':\n",
    "        dados_teste = dados_teste.replace(dados_teste['Teste'][i], dados_teste['Teste'][i][3:])\n",
    "        \n",
    "    # Deixando todas as letras min√∫sculas:\n",
    "    dados_teste = dados_teste.replace(dados_teste['Teste'][i], dados_teste['Teste'][i].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fwit olympics httpstco72go6l7pkx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@jimodonnell2 its certainly a supportable opin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@kapil857 @kapil857 any link to know how point...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@media_sai what a superb performance by @simra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@theeconomist japan may have to cancel the oly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>study tokyo 2020 cancellation could see japan‚Äô...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>japanese doctors report sharp falls in cases o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>@jimmfelton ‚Äúvirus is bad might have to cancel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>@drjitendrasingh eight indian boxers including...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>the international olympic committee and local ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  Classification\n",
       "0                    fwit olympics httpstco72go6l7pkx               0\n",
       "1   @jimodonnell2 its certainly a supportable opin...               1\n",
       "2   @kapil857 @kapil857 any link to know how point...               0\n",
       "3   @media_sai what a superb performance by @simra...               0\n",
       "4   @theeconomist japan may have to cancel the oly...               1\n",
       "..                                                ...             ...\n",
       "95  study tokyo 2020 cancellation could see japan‚Äô...               1\n",
       "96  japanese doctors report sharp falls in cases o...               0\n",
       "97  @jimmfelton ‚Äúvirus is bad might have to cancel...               0\n",
       "98  @drjitendrasingh eight indian boxers including...               1\n",
       "99  the international olympic committee and local ...               1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para classificarmos os tweets de teste, iremos usar a seguinte desigualdade:<br>\n",
    "$$P(R|tweet) > P(IR|tweet)$$\n",
    "Onde estamos verificando se a probabilidade de ser relevante √© maior que a de ser irrelevante.\n",
    "Mas pela lei de Na√Øve-Bayes temos:<br>\n",
    "$$P(R|tweet) = \\frac{P(tweet|R)P(R)}{P(tweet)}$$\n",
    "<br>\n",
    "$$P(IR|tweet) = \\frac{P(tweet|IR)P(IR)}{P(tweet)}$$<br>\n",
    "Como o denominador √© comum a ambos, iremos comparar apenas os numeradores. Para isso, come√ßaremos calculando $P(R)$ e $P(IR)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3412735627872081"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de uma maneira bem simplista:\n",
    "P_R = len(txt_r.split())/len(txt.split())\n",
    "P_IR = len(txt_ir.split())/len(txt.split())\n",
    "P_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6587264372127919"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora calcularemos o P(tweet|R) e P(tweet|IR)\n",
    "# perceba que esses s√£o apenas o produto das probabilidades das palavras contidas nos tweets\n",
    "# dado que s√£o relevantes ou irrelevantes\n",
    "P_TdadoR, P_TdadoIR = P_R, P_IR\n",
    "\n",
    "# salvaremos os resultados numa lista para comparar depois\n",
    "lista_relevante, lista_irrelevante = [], []\n",
    "\n",
    "for tweet in dados_teste.Teste:\n",
    "    for word in tweet.split():\n",
    "        if word not in words_r:\n",
    "            # aqui estamos desconsiderando palavras que n√£o est√£o nesse espa√ßo amostral\n",
    "            pass\n",
    "        else:\n",
    "            P_TdadoR *= words_r[word]\n",
    "    lista_relevante.append(P_TdadoR)\n",
    "    P_TdadoR = P_R\n",
    "len(lista_relevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tweet in dados_teste.Teste:\n",
    "    for word in tweet.split():\n",
    "        if word not in words_ir:\n",
    "            # aqui estamos desconsiderando palavras que n√£o est√£o nesse espa√ßo amostral\n",
    "            pass\n",
    "        else:\n",
    "            P_TdadoIR *= words_ir[word]\n",
    "    lista_irrelevante.append(P_TdadoIR)\n",
    "    P_TdadoIR = P_IR\n",
    "len(lista_irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Classifica√ß√£o NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fwit olympics httpstco72go6l7pkx</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@jimodonnell2 its certainly a supportable opin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@kapil857 @kapil857 any link to know how point...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@media_sai what a superb performance by @simra...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@theeconomist japan may have to cancel the oly...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>study tokyo 2020 cancellation could see japan‚Äô...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>japanese doctors report sharp falls in cases o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>@jimmfelton ‚Äúvirus is bad might have to cancel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>@drjitendrasingh eight indian boxers including...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>the international olympic committee and local ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  Classification  \\\n",
       "0                    fwit olympics httpstco72go6l7pkx               0   \n",
       "1   @jimodonnell2 its certainly a supportable opin...               1   \n",
       "2   @kapil857 @kapil857 any link to know how point...               0   \n",
       "3   @media_sai what a superb performance by @simra...               0   \n",
       "4   @theeconomist japan may have to cancel the oly...               1   \n",
       "..                                                ...             ...   \n",
       "95  study tokyo 2020 cancellation could see japan‚Äô...               1   \n",
       "96  japanese doctors report sharp falls in cases o...               0   \n",
       "97  @jimmfelton ‚Äúvirus is bad might have to cancel...               0   \n",
       "98  @drjitendrasingh eight indian boxers including...               1   \n",
       "99  the international olympic committee and local ...               1   \n",
       "\n",
       "    Classifica√ß√£o NB  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  \n",
       "..               ...  \n",
       "95                 1  \n",
       "96                 1  \n",
       "97                 0  \n",
       "98                 0  \n",
       "99                 1  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora vamos criar uma nova coluna no dataframe com a classifica√ß√£o segundo o classificador\n",
    "classificador_NB = []\n",
    "for i in range(len(lista_irrelevante)):\n",
    "    if lista_irrelevante[i] > lista_relevante[i]:\n",
    "        classificador_NB.append(0)\n",
    "    else:\n",
    "        classificador_NB.append(1)\n",
    "dados_teste['Classifica√ß√£o NB'] = classificador_NB\n",
    "dados_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tivemos um total de 37% de acertos\n"
     ]
    }
   ],
   "source": [
    "# calculando a acur√°cia:\n",
    "acertos = 0\n",
    "for i in range(100):\n",
    "    if dados_teste['Classification'][i] == dados_teste['Classifica√ß√£o NB'][i]:\n",
    "        acertos += 1\n",
    "print('Tivemos um total de {0}% de acertos' .format(acertos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classifica√ß√£o NB</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classification</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classifica√ß√£o NB   0   1\n",
       "Classification          \n",
       "0                 11  41\n",
       "1                 22  26"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab = pd.crosstab(dados_teste['Classification'],dados_teste['Classifica√ß√£o NB'])\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os resultados foram:\n",
      "\t11% s√£o verdadeiros negativos\n",
      "\t41% s√£o falsos negativos\n",
      "\t22% s√£o falsos positivos\n",
      "\t26% s√£o verdadeiros positivos\n"
     ]
    }
   ],
   "source": [
    "print('Os resultados foram:\\n\\t{0}% s√£o verdadeiros negativos\\n\\t{1}% s√£o falsos negativos\\n\\t{2}% s√£o falsos positivos\\n\\t{3}% s√£o verdadeiros positivos' .format(crosstab[0][0], crosstab[1][0], crosstab[0][1], crosstab[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Podemos perceber que o nosso modelo correspondeu com a classifica√ß√£o inicial em 37% dos casos, entretanto, esse resultado √© influenciado por fatores que n√£o foram contabilizados e que poderia ter influenciado esse n√∫mero negativamente ou positivamente.\n",
    "\n",
    "Nosso classificador, por exemplo, faz uma an√°lise muito simples e quantitativa e n√£o leva em conta fatores como sarcasmo, quem foram os usu√°rios marcados em uma postagem ou o significado cultural de um emoji e o contexto em que o tweet foi postado. Al√©m do vi√©s daqueles que classificaram inicialmente os tweets.\n",
    "\n",
    "Podemos ainda refletir sobre as implica√ß√µes de usar um modelo como esse para outros temas. Algu√©m que use esse modelo para prever o sentimento de pessoas quanto a um candidato X ou Y nas elei√ß√µes presidenciais em um pa√≠s poderia manipular os resultados a favor de um deste, uma vez que ele pr√≥prio classificou os tweets usados para treinamento. Ou seja, o modelo de Na√Øve-Bayes n√£o √© recomendado para situa√ß√µes t√£o delicadas.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Explica√ß√£o de porque n√£o podemos usar o classificador para gerar mais amostras </h3>\n",
    "<br>\n",
    "Como dito na conclus√£o, nosso modelo √© muito simples e s√≥ considera aspectos matem√°ticos para tomar sua decis√£o. Por isso ele n√£o √© recomendado para julgar assuntos que dependam de aspectos t√£o humanos, como sarcasmo. Al√©m de ele estar cheio de vi√©s de quem criou a classifica√ß√£o inicial. Us√°-lo para gerar mais amostras de treinamento faria com que ele tivesse uma acur√°cia de 100% quando testado com estas, o que resultaria num caso de overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Proposi√ß√£o de outros cen√°rios para Na√Øve-Bayes </h3>\n",
    "<br>\n",
    "Ainda na conclus√£o dissemos que esse algoritmo n√£o √© aconselhado para situa√ß√µes t√£o delicadas como elei√ß√µes, j√° que as conclus√µes podem alterar din√¢micas pol√≠ticas, econ√¥micas e sociais.\n",
    "Ele tamb√©m n√£o √© recomendado para dar diagnosticos a pacientes internados sobre suas chances de sobreviv√™ncia.\n",
    "Entretanto, podemos usar esse para procurar e filtrar na internet tweets, posts de facebook, not√≠cias em sites ou qualquer outro texto que tenha rela√ß√£o com assuntos mais concretos e menos sens√≠veis como textos que falem sobre o novo Corona v√≠rus ou textos que falem sobre Ci√™ncia de Dados, j√° que estes costumam conter um jarg√£o e escolhas de palavras bem caracter√≠stico. Al√©m de que classificar um texto sobre o Corona v√≠rus erroneamente como sendo um texto sobre chinelos Havainas n√£o teria repercuss√£o t√£o grande na sociedade quanto dizer que o candidato X tem mais chances que o Y. Por isso estas situa√ß√µes podem fazer uso de Na√Øve-Bayes perfeitamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sugest√£o de melhorias </h3>\n",
    "<br>\n",
    "Algumas poss√≠veis melhorias a serem feitas s√£o:\n",
    "<h5>1. Conseguir mais tweets de treinamento e dividir a classifica√ß√£o inicial entre mais pessoas (de prefer√™ncia com ciclos sociais e culturais diferentes)</h5>\n",
    "Essa melhoria √© eficaz n√£o s√≥ porque ter√≠amos uma base de dados para treino maior (e consequentemente mais palavras) mas tamb√©m porque dilui o vi√©s da classifica√ß√£o inicial entre pessoas que pensam diferente e tomam decis√µes diferentes;\n",
    "<h5>2. Usar artif√≠cios como cross-validation</h5>\n",
    "Um conceito comum em machine learning que consiste em separar o dataframe de treino em dataframes menores, treinar o modelo sobre alguns destes e testar em outros e fazer isso um n√∫mero grande de vezes antes de testar no dataframe de testes. Segue um link para como podemos fazer isso explicado por professores do Kaggle:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
